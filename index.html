<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>
    Fast and Accurate Illumination Estimation Using LDR Panoramic Images for Realistic Rendering
  </title>
  <meta name="description" content="">

  <link rel="stylesheet" href="./files/style.css">
  <link rel="stylesheet" href="./files/bootstrap-grid.min.css">
  <link rel="stylesheet" href="./files/katex.min.css">
  <link rel="stylesheet" href="./files/all.css">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true
  },
  "HTML-CSS": {
  scale: 100
}
});
</script><script type="text/javascript" src="./files/MathJax.js"></script></head>


<!-- MathJax Script -->



<body>
  <div class="page-content">
    <div class="wrapper">

      <article class="post">

        <header class="post-header">
          <!-- Paper title -->
          <h1 class="post-title">Fast and Accurate Illumination Estimation Using LDR Panoramic Images for Realistic Rendering</h1>

          <!-- Authors -->
          <ul class="authors">

            <li>
              <a href="https://github.com/AplusX">Haojie Cheng</a>,
              University of Science and Technology of China
            </li>

            <li>
              <a href="https://github.com/feimos32">Chunxiao Xu</a>,
              University of Science and Technology of China
            </li>
			
		   <li>
             <a href="">Jiajun Wang</a>,
             Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Science
           </li>
		   
		    <li>
             <a href="">Zhenxin Chen</a>,
             Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Science
           </li>
 
		    <li>
             <a href="">Lingxiao Zhao</a>,
             University of Science and Technology of China
           </li>
         </ul>

         <!-- Journal/conference title -->
         <p>In 
          <i>IEEE Transactions on Visualization and Computer Graphics (TVCG)</i>, 2022<br>
        </p>

        <!-- Teaser figure-->
        <figure>
          <a href="./files/teaser.png"><img src="./files/teaser.png" class="teaser"></a>
		  
<!--           <p style="font-size:13px" class="justified">We propose a novel deep learning system for single image HDR reconstruction by synthesizing visually pleasing details in the saturated areas. We introduce a new feature masking approach that reduces the contribution of the features computed on the saturated areas, to mitigate halo and checkerboard artifacts. To synthesize visually pleasing textures in the saturated regions, we adapt the VGG-based perceptual loss function to the HDR reconstruction application. Furthermore, to effectively train our network on limited HDR training data, we propose to pre-train the network on inpainting task. Our method can reconstruct regions with high luminance, such as the bright highlights of the windows (red inset), and generate visually pleasing textures (green insert). See Figure 7 for comparison against several other approaches. All images have been gamma corrected for display purposes.</p> -->
        </figure>
      </header>

      <div class="post-content">
        <!-- Abstract -->
        <h1>Abstract</h1>
        <p class="justified">A high dynamic range (HDR) image is commonly used to reveal stereo illumination, which is crucial for generating high-quality realistic rendering effects. Compared to the high-cost HDR imaging technique, low dynamic range (LDR) imaging provides a low-cost alternative and is preferable for interactive graphics applications. However, the limited LDR pixel bit depth significantly bothers accurate illumination estimation using LDR images. The conflict between the realism and promptness of illumination estimation for realistic rendering is yet to be resolved. In this paper, an efficient method that accurately infers illuminations of real-world scenes using LDR panoramic images is proposed. It estimates multiple lighting parameters, including locations, types and intensities of light sources. In our approach, a new algorithm that extracts illuminant characteristics during the exposure attenuation process is developed to locate light sources and outline their boundaries. To better predict realistic illuminations, a new deep learning model is designed to efficiently parse complex LDR panoramas and classify detected light sources. Finally, realistic illumination intensities are calculated by recovering the inverse camera response function and extending the dynamic range of pixel values based on previously estimated parameters of light sources. The reconstructed radiance map can be used to compute high-quality image-based lighting of virtual models. Experimental results demonstrate that the proposed method is capable of efficiently and accurately computing comprehensive illuminations using LDR images. Our method can be used to produce better realistic rendering results than existing approaches.</p>

        <!-- Download links -->

	    <!-- Video embedding -->
		<h1>Video</h1>
		<div class="video-container">
		  <iframe frameborder="0" class="video" src="https://www.youtube.com/embed/UngsVeLN3Sk?si=eaOid5NnlvzQodLJ"></iframe>
		</div>


        <h1>Downloads</h1>
        <p>
        </p><h3>Publication</h3>
        <ul class="fa-ul">
          <li><span class="fa-li"><i class="far fa-file-pdf"></i></span>
            <a href="./files/Fast_and_Accurate_Illumination_Estimation_Using_LDR_Panoramic_Images_for_Realistic_Rendering.pdf">Paper, PDF (10.2 MB)</a>
          </li>
        </ul>

        <h3>Supplementals</h3>
        <ul class="fa-ul">
		  <li><span class="fa-li"><i class="far fa-file-pdf"></i></span>
            <a href="./files/Supplementary Material.pdf">Supplementary material, PDF (24.7 MB)</a>
          </li>
		  
          <li><span class="fa-li"><i class="far fa-file-pdf"></i></span>
            <a href="https://drive.google.com/file/d/17-aAgpRNivT7XZ4BNZKMd5iKl-EwLREh/view?usp=drive_link">Supplementary material, Video (63.7 MB)</a>
          </li>

        </ul>
        
        <p></p>


        <!-- Thanks -->
<!--         <h1>Acknowledgments</h1>
        <p class="justified">
          We thank the reviewers for their constructive comments. The website template was borrowed from <a href="https://joeylitalien.github.io/">Joey Litalien</a>.
        </p> -->


        <!-- BibTeX citation -->

        <h1>Cite</h1>
        <blockquote class="justified">

          <a href="https://github.com/AplusX">Haojie Cheng</a>,

          <a href="https://github.com/feimos32">Chunxiao Xu</a>
		  
		  <a href="">Jiajun Wang</a>
		  
		  <a href="">Zhenxin Chen</a>
		 
          and 

          <a href="">Lingxiao Zhao</a>.

         Fast and Accurate Illumination Estimation Using LDR Panoramic Images for Realistic Rendering. <i>IEEE Transactions on Visualization and Computer Graphics (TVCG)</i>, 2022, pp. 1-15, doi: 10.1109/TVCG.2022.3205614.
        </blockquote>

		<pre><code>@article{Cheng2022,
  author   = "Cheng, Haojie and Xu, Chunxiao and Wang, Jiajun and Chen, Zhenxin and Zhao, Lingxiao",
  title    = "{Fast and Accurate Illumination Estimation Using LDR Panoramic Images for Realistic Rendering}",
  journal  = "IEEE Transactions on Visualization and Computer Graphics",
  year     = "2022",
  month    = "Sep",
  volume   = "29",
  number   = "12",
  doi      = {10.1109/TVCG.2022.3205614},
  pages    = "5235--5249"
}
</code></pre>



     <!-- Other content -->


   </div>

 </article>

</div>
</div>

<script src="https://kit.fontawesome.com/8aad4879fb.js" crossorigin="anonymous"></script>
</body></html>