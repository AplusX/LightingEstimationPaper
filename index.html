<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>
    Realistic Volume Rendering with Environment-Synced Illumination in Mixed Reality
  </title>
  <meta name="description" content="">

  <link rel="stylesheet" href="./files/style.css">
  <link rel="stylesheet" href="./files/bootstrap-grid.min.css">
  <link rel="stylesheet" href="./files/katex.min.css">
  <link rel="stylesheet" href="./files/all.css">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true
  },
  "HTML-CSS": {
  scale: 100
}
});
</script><script type="text/javascript" src="./files/MathJax.js"></script></head>


<!-- MathJax Script -->



<body>
  <div class="page-content">
    <div class="wrapper">

      <article class="post">

        <header class="post-header">
          <!-- Paper title -->
          <h1 class="post-title">Realistic Volume Rendering with Environment-Synced Illumination in Mixed Reality</h1>

          <!-- Authors -->
          <ul class="authors">

            <li>
              <a href="https://github.com/AplusX">Haojie Cheng</a>,
              University of Science and Technology of China
            </li>

            <li>
              <a href="https://github.com/feimos32">Chunxiao Xu</a>,
              University of Science and Technology of China
            </li>
			
			<li>
             <a href="">Xujing Chen</a>,
              University of Science and Technology of China
           </li>
		   
		    <li>
             <a href="">Zhenxin Chen</a>,
             Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Science
           </li>
		   
            <li>
             <a href="">Jiajun Wang</a>,
             Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Science
           </li>
 
		    <li>
             <a href="">Lingxiao Zhao</a>,
             University of Science and Technology of China
           </li>
         </ul>

         <!-- Journal/conference title -->
         <p>In 
          <i>IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR Adjunct)</i>, 2023<br>
        </p>

        <!-- Teaser figure-->
        <figure>
          <a href="./files/teaser.png"><img src="./files/teaser.png" class="teaser"></a>
		  
<!--           <p style="font-size:13px" class="justified">We propose a novel deep learning system for single image HDR reconstruction by synthesizing visually pleasing details in the saturated areas. We introduce a new feature masking approach that reduces the contribution of the features computed on the saturated areas, to mitigate halo and checkerboard artifacts. To synthesize visually pleasing textures in the saturated regions, we adapt the VGG-based perceptual loss function to the HDR reconstruction application. Furthermore, to effectively train our network on limited HDR training data, we propose to pre-train the network on inpainting task. Our method can reconstruct regions with high luminance, such as the bright highlights of the windows (red inset), and generate visually pleasing textures (green insert). See Figure 7 for comparison against several other approaches. All images have been gamma corrected for display purposes.</p> -->
        </figure>
      </header>

      <div class="post-content">
        <!-- Abstract -->
        <h1>Abstract</h1>
        <p class="justified">Interactive volume visualization using a mixed reality (MR) system helps provide users with an intuitive spatial perception of volumetric data. Due to sophisticated requirements of user interaction and vision when using MR head-mounted display (HMD) devices, the conflict between the realisticness and efficiency of direct volume rendering (DVR) is yet to be resolved. In this paper, a new MR visualization framework that supports interactive realistic DVR is proposed. An efficient illumination estimation method is used to identify the high dynamic range (HDR) environment illumination captured using a panorama camera. To improve the visual quality of Monte Carlo-based DVR, a new spatio-temporal denoising algorithm is designed. Based on a reprojection strategy, it makes full use of temporal coherence between adjacent frames and spatial coherence between the two screens of an HMD to optimize MR rendering quality. Several MR development modules are also developed for related devices to efficiently and stably display the DVR results in an MR HMD. Experimental results demonstrate that our framework can better support immersive and intuitive user perception during MR viewing than existing MR solutions.</p>

        <!-- Download links -->

	    <!-- Video embedding -->
		<h1>Video</h1>
		<div class="video-container">
		  <iframe frameborder="0" class="video" src="https://youtu.be/OvbPDrfDdkg"></iframe>
		</div>


        <h1>Downloads</h1>
        <p>
        </p><h3>Publication</h3>
        <ul class="fa-ul">
          <li><span class="fa-li"><i class="far fa-file-pdf"></i></span>
            <a href="./files/ISMAR-Adjunct-Paper.pdf">Paper, PDF (10.2MB)</a>
          </li>
        </ul>

        <h3>Supplementals</h3>
        <ul class="fa-ul">
		  <li><span class="fa-li"><i class="far fa-file-pdf"></i></span>
            <a href="">Supplementary material, PDF (27.5MB)</a>
          </li>
		  
          <li><span class="fa-li"><i class="far fa-file-pdf"></i></span>
            <a href="https://drive.google.com/file/d/1vGyldUoijSV7JzGVXOgs4Y2QWJsRtbFc/view?usp=drive_link">Supplementary material, Video (168MB)</a>
          </li>

        </ul>
        
        <p></p>


        <!-- Thanks -->
<!--         <h1>Acknowledgments</h1>
        <p class="justified">
          We thank the reviewers for their constructive comments. The website template was borrowed from <a href="https://joeylitalien.github.io/">Joey Litalien</a>.
        </p> -->


        <!-- BibTeX citation -->

        <h1>Cite</h1>
        <blockquote class="justified">

          <a href="https://github.com/AplusX">Haojie Cheng</a>,

          <a href="https://github.com/feimos32">Chunxiao Xu</a>
		  
		  <a href="">Xujing Chen</a>
		  
		  <a href="">Zhenxin Chen</a>
		  
		  <a href="">Jiajun Wang</a>

          and 

          <a href="">Lingxiao Zhao</a>.

         Realistic Volume Rendering with Environment-Synced Illumination in Mixed Reality. <i>IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR Adjunct)</i>, 2023: 1-6, Accepted.
        </blockquote>

		<pre><code>@article{Cheng2023MRrendering,
		  author  = "Cheng, Haojie and Xu, Chunxiao and Chen, Xujing and Chen, Zhenxin and Wang, Jiajun and Zhao, Lingxiao",
		  title   = "{Realistic Volume Rendering with Environment-Synced Illumination in Mixed Reality}",
		  journal = "IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR Adjunct)",
		  year    = "2023",
		  pages   = "1--6"
		}
</code></pre>



     <!-- Other content -->


   </div>

 </article>

</div>
</div>

<script src="https://kit.fontawesome.com/8aad4879fb.js" crossorigin="anonymous"></script>
</body></html>